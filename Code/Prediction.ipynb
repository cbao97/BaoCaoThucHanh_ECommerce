{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c91262-4ea7-4e62-ab18-6f688d88612b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "#We will be using Keras IMDB dataset. vocabulary size is a parameter \n",
    "#that is used the get data containing the given number of most occurring words in the entire corpus of textual data. \n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2908bafd-ea96-4fb9-9d96-0bc01a30c0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"SimpleRNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_23 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 128)               20608     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 180,737\n",
      "Trainable params: 180,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[0.46059188]\n",
      " [0.4570467 ]\n",
      " [0.46609864]\n",
      " [0.46061403]\n",
      " [0.47009686]\n",
      " [0.47222224]\n",
      " [0.44586992]\n",
      " [0.46600774]\n",
      " [0.469097  ]\n",
      " [0.47146964]\n",
      " [0.4671556 ]\n",
      " [0.4760411 ]], shape=(12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('C:/Users/hai/hai_data_dxl/News050523_hai.csv')\n",
    "\n",
    "# Tiền xử lý dữ liệu nếu cần\n",
    "# ...\n",
    "\n",
    "embd_len = 32\n",
    "max_words = 500\n",
    "vocab_size = 5000\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành một tensor hoặc đối tượng có cấu trúc tương tự\n",
    "input_data = np.array(data['new_content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(input_data)\n",
    "\n",
    "# Chuyển đổi văn bản thành chỉ số\n",
    "sequences = tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "# Đảm bảo độ dài cố định của mỗi mẫu\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_words)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(padded_sequences)\n",
    "\n",
    "# Creating a RNN model\n",
    "RNN_model = Sequential(name=\"SimpleRNN\")\n",
    "RNN_model.add(Embedding(vocab_size,\n",
    "\t\t\t\t\t\tembd_len,\n",
    "\t\t\t\t\t\tinput_length=max_words))\n",
    "\n",
    "# In case of a stacked(more than one layer of RNN)\n",
    "# use return_sequences=True\n",
    "RNN_model.add(SimpleRNN(128,\n",
    "\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=False))\n",
    "RNN_model.add(Dropout(0.2)) \n",
    "RNN_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# printing model summary\n",
    "print(RNN_model.summary())\n",
    "\n",
    "# Compiling model\n",
    "RNN_model.compile(\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\toptimizer='adam',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def predict_fn(input_tensor):\n",
    "    return RNN_model(input_tensor)\n",
    "\n",
    "predictions = predict_fn(input_tensor)\n",
    "print(predictions)\n",
    "\n",
    "# Lấy giá trị dự đoán\n",
    "values = predictions.numpy().flatten()\n",
    "\n",
    "# Tạo DataFrame từ giá trị dự đoán\n",
    "df_predictions = pd.DataFrame({'Model_name':'RNN','Value': values})\n",
    "\n",
    "# Lưu vào file CSV\n",
    "df_predictions.to_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d462af39-88bd-4edc-add5-24aaa9fe717e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_26 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 128)               62208     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,337\n",
      "Trainable params: 222,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]\n",
      " [0.49550107]], shape=(12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('C:/Users/hai/hai_data_dxl/News050523_hai.csv')\n",
    "\n",
    "# Tiền xử lý dữ liệu nếu cần\n",
    "# ...\n",
    "\n",
    "embd_len = 32\n",
    "max_words = 500\n",
    "vocab_size = 5000\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành một tensor hoặc đối tượng có cấu trúc tương tự\n",
    "input_data = np.array(data['new_content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(input_data)\n",
    "\n",
    "# Chuyển đổi văn bản thành chỉ số\n",
    "sequences = tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "# Đảm bảo độ dài cố định của mỗi mẫu\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_words)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(padded_sequences)\n",
    "\n",
    "# Creating a RNN model\n",
    "gru_model = Sequential(name=\"GRU\")\n",
    "gru_model.add(Embedding(vocab_size,\n",
    "\t\t\t\t\t\tembd_len,\n",
    "\t\t\t\t\t\tinput_length=max_words))\n",
    "\n",
    "# In case of a stacked(more than one layer of RNN)\n",
    "# use return_sequences=True\n",
    "gru_model.add(GRU(128,\n",
    "\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=False))\n",
    "gru_model.add(Dropout(0.2)) \n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# printing model summary\n",
    "print(gru_model.summary())\n",
    "\n",
    "# Compiling model\n",
    "gru_model.compile(\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\toptimizer='adam',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "\n",
    "@tf.function\n",
    "def predict_fn(input_tensor):\n",
    "    return gru_model(input_tensor)\n",
    "\n",
    "predictions1 = predict_fn(input_tensor)\n",
    "print(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2b05f6a-47a0-4ed1-a3a7-0b617e9808a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy giá trị dự đoán\n",
    "values = predictions1.numpy().flatten()\n",
    "\n",
    "# Đọc dữ liệu cũ từ tệp CSV hoặc cơ sở dữ liệu\n",
    "old_data = pd.read_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv')\n",
    "\n",
    "# Thêm dữ liệu mới vào DataFrame\n",
    "new_data = pd.DataFrame({'Model_name':'GRU','Value': values})\n",
    "\n",
    "# Ghi dữ liệu mới vào tệp CSV hoặc cơ sở dữ liệu\n",
    "new_data.to_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5787945d-1b53-4123-abdf-a5d255dd0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_31 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm_18 (LSTM)              (None, 128)               82432     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 242,561\n",
      "Trainable params: 242,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]\n",
      " [0.4981125]], shape=(12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('C:/Users/hai/hai_data_dxl/News050523_hai.csv')\n",
    "\n",
    "# Tiền xử lý dữ liệu nếu cần\n",
    "# ...\n",
    "\n",
    "embd_len = 32\n",
    "max_words = 500\n",
    "vocab_size = 5000\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành một tensor hoặc đối tượng có cấu trúc tương tự\n",
    "input_data = np.array(data['new_content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(input_data)\n",
    "\n",
    "# Chuyển đổi văn bản thành chỉ số\n",
    "sequences = tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "# Đảm bảo độ dài cố định của mỗi mẫu\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_words)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(padded_sequences)\n",
    "\n",
    "# Creating a RNN model\n",
    "lstm_model = Sequential(name=\"LSTM\")\n",
    "lstm_model.add(Embedding(vocab_size,\n",
    "\t\t\t\t\t\tembd_len,\n",
    "\t\t\t\t\t\tinput_length=max_words))\n",
    "\n",
    "# In case of a stacked(more than one layer of RNN)\n",
    "# use return_sequences=True\n",
    "lstm_model.add(LSTM(128,\n",
    "\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=False))\n",
    "lstm_model.add(Dropout(0.2)) \n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# printing model summary\n",
    "print(lstm_model.summary())\n",
    "\n",
    "# Compiling model\n",
    "lstm_model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "# Thực hiện dự đoán\n",
    "@tf.function\n",
    "def predict_fn(input_tensor):\n",
    "    return lstm_model(input_tensor)\n",
    "\n",
    "predictions2 = predict_fn(input_tensor)\n",
    "print(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e6a244a-7a25-43a9-92a2-3b10ff7cd851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy giá trị dự đoán\n",
    "values = predictions2.numpy().flatten()\n",
    "\n",
    "# Đọc dữ liệu cũ từ tệp CSV hoặc cơ sở dữ liệu\n",
    "old_data = pd.read_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv')\n",
    "\n",
    "# Thêm dữ liệu mới vào DataFrame\n",
    "new_data = pd.DataFrame({'Model_name':'LSTM','Value': values})\n",
    "\n",
    "# Ghi dữ liệu mới vào tệp CSV hoặc cơ sở dữ liệu\n",
    "new_data.to_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "08cf57ad-f64e-4c9e-8f35-d9d43c947976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bi-LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_33 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 256)              164864    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 325,121\n",
      "Trainable params: 325,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[0.4979275 ]\n",
      " [0.49963146]\n",
      " [0.49847096]\n",
      " [0.49836588]\n",
      " [0.4974691 ]\n",
      " [0.49939904]\n",
      " [0.49766377]\n",
      " [0.4988221 ]\n",
      " [0.49826112]\n",
      " [0.49802852]\n",
      " [0.49939364]\n",
      " [0.4985756 ]], shape=(12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('C:/Users/hai/hai_data_dxl/News050523_hai.csv')\n",
    "\n",
    "# Tiền xử lý dữ liệu nếu cần\n",
    "# ...\n",
    "\n",
    "embd_len = 32\n",
    "max_words = 500\n",
    "vocab_size = 5000\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành một tensor hoặc đối tượng có cấu trúc tương tự\n",
    "input_data = np.array(data['new_content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(input_data)\n",
    "\n",
    "# Chuyển đổi văn bản thành chỉ số\n",
    "sequences = tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "# Đảm bảo độ dài cố định của mỗi mẫu\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_words)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(padded_sequences)\n",
    "\n",
    "# Creating a Bi-LSTM model\n",
    "bi_lstm_model = Sequential(name=\"Bi-LSTM\")\n",
    "bi_lstm_model.add(Embedding(vocab_size,\n",
    "\t\t\t\t\t\tembd_len,\n",
    "\t\t\t\t\t\tinput_length=max_words))\n",
    "\n",
    "# In case of a stacked(more than one layer of RNN)\n",
    "# use return_sequences=True\n",
    "bi_lstm_model.add(Bidirectional(LSTM(128,\n",
    "\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=False)))\n",
    "bi_lstm_model.add(Dropout(0.2)) \n",
    "bi_lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# printing model summary\n",
    "print(bi_lstm_model.summary())\n",
    "\n",
    "# Compiling model\n",
    "bi_lstm_model.compile(\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\toptimizer='adam',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "# Thực hiện dự đoán\n",
    "@tf.function\n",
    "def predict_fn(input_tensor):\n",
    "    return bi_lstm_model(input_tensor)\n",
    "\n",
    "predictions3 = predict_fn(input_tensor)\n",
    "print(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6e8a6051-a5a1-45da-a08c-11791afce94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy giá trị dự đoán\n",
    "values = predictions3.numpy().flatten()\n",
    "\n",
    "# Đọc dữ liệu cũ từ tệp CSV hoặc cơ sở dữ liệu\n",
    "old_data = pd.read_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv')\n",
    "\n",
    "# Thêm dữ liệu mới vào DataFrame\n",
    "new_data = pd.DataFrame({'Model_name':'BiLSTM','Value': values})\n",
    "\n",
    "# Ghi dữ liệu mới vào tệp CSV hoặc cơ sở dữ liệu\n",
    "new_data.to_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8ae63cf-6ad3-45c1-97d8-d74bba24849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Bi-GRU\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_34 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 256)              124416    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 284,673\n",
      "Trainable params: 284,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "tf.Tensor(\n",
      "[[0.49487156]\n",
      " [0.49568006]\n",
      " [0.49162993]\n",
      " [0.49088183]\n",
      " [0.4953909 ]\n",
      " [0.49479347]\n",
      " [0.49541613]\n",
      " [0.49735788]\n",
      " [0.49298126]\n",
      " [0.49379417]\n",
      " [0.48837873]\n",
      " [0.49673173]], shape=(12, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "data = pd.read_csv('C:/Users/hai/hai_data_dxl/News050523_hai.csv')\n",
    "\n",
    "# Tiền xử lý dữ liệu nếu cần\n",
    "# ...\n",
    "\n",
    "embd_len = 32\n",
    "max_words = 500\n",
    "vocab_size = 5000\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào thành một tensor hoặc đối tượng có cấu trúc tương tự\n",
    "input_data = np.array(data['new_content'])\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(input_data)\n",
    "\n",
    "# Chuyển đổi văn bản thành chỉ số\n",
    "sequences = tokenizer.texts_to_sequences(input_data)\n",
    "\n",
    "# Đảm bảo độ dài cố định của mỗi mẫu\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_words)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(padded_sequences)\n",
    "\n",
    "# Creating a RNN model\n",
    "bi_gru_model = Sequential(name=\"Bi-GRU\")\n",
    "bi_gru_model.add(Embedding(vocab_size,\n",
    "\t\t\t\t\t\tembd_len,\n",
    "\t\t\t\t\t\tinput_length=max_words))\n",
    "\n",
    "# In case of a stacked(more than one layer of RNN)\n",
    "# use return_sequences=True\n",
    "bi_gru_model.add(Bidirectional(GRU(128,\n",
    "\t\t\t\t\t\tactivation='tanh',\n",
    "\t\t\t\t\t\treturn_sequences=False)))\n",
    "bi_gru_model.add(Dropout(0.2)) \n",
    "bi_gru_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# printing model summary\n",
    "print(bi_gru_model.summary())\n",
    "\n",
    "# Compiling model\n",
    "bi_gru_model.compile(\n",
    "\tloss=\"binary_crossentropy\",\n",
    "\toptimizer='adam',\n",
    "\tmetrics=['accuracy']\n",
    ")\n",
    "# Thực hiện dự đoán\n",
    "@tf.function\n",
    "def predict_fn(input_tensor):\n",
    "    return bi_gru_model(input_tensor)\n",
    "\n",
    "predictions4 = predict_fn(input_tensor)\n",
    "print(predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e0a952e-417f-40aa-8fa6-eb2bcc0fec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy giá trị dự đoán\n",
    "values = predictions4.numpy().flatten()\n",
    "\n",
    "# Đọc dữ liệu cũ từ tệp CSV hoặc cơ sở dữ liệu\n",
    "old_data = pd.read_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv')\n",
    "\n",
    "# Thêm dữ liệu mới vào DataFrame\n",
    "new_data = pd.DataFrame({'Model_name':'BGRU','Value': values})\n",
    "\n",
    "# Ghi dữ liệu mới vào tệp CSV hoặc cơ sở dữ liệu\n",
    "new_data.to_csv('C:/Users/hai/DuLieuKQTN/Prediction0505.csv', mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682c2b22-765c-4e37-ac56-21d1f13bcece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
